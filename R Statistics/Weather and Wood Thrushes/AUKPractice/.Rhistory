ebd <- auk_ebd("/Users/kimberlyadams/Documents/Bellevue Masters in Data Science/3 Statistics and R/Project/eBird Sample Data/ebd_US-AL-101_202204_202204_relApr-2022.txt", sep = "\t")
head(ebd)
# output files
data_dir <- "eBirdData"
if (!dir.exists(data_dir)) {
dir.create(data_dir) }
f_ebd <- file.path(data_dir, "sampledata.txt")
# only run if the files don't already exist
if (!file.exists(f_ebd)) {
f_sampling <- file.path(data_dir, "ebd_US-AL-101_202204_202204_relApr-2022.txt")
auk_filter(ebd_filters, file = f_ebd, file_sampling = f_sampling)
}
View(f_ebd)
# resolve namespace conflicts
select <- dplyr::select
# setup data directory
dir.create("eBirdData", showWarnings = FALSE)
ebd <- auk_ebd("/Users/kimberlyadams/Documents/Bellevue Masters in Data Science/3 Statistics and R/Project/eBird Sample Data/ebd_US-AL-101_202204_202204_relApr-2022.txt", sep = "\t")
head(ebd)
# output files
data_dir <- "eBirdData"
if (!dir.exists(data_dir)) {
dir.create(data_dir) }
f_ebd <- file.path(data_dir, "sampledata.txt")
# only run if the files don't already exist
if (!file.exists(f_ebd)) {
f_sampling <- file.path(data_dir, "ebd_US-AL-101_202204_202204_relApr-2022.txt")
auk_filter(ebd_filters, file = f_ebd, file_sampling = f_sampling, overwrite = TRUE)
}
View(f_ebd)
# resolve namespace conflicts
select <- dplyr::select
# setup data directory
dir.create("eBirdData", showWarnings = FALSE)
ebd <- auk_ebd("/Users/kimberlyadams/Documents/Bellevue Masters in Data Science/3 Statistics and R/Project/eBird Sample Data/ebd_US-AL-101_202204_202204_relApr-2022.txt", sep = "\t")
head(ebd)
# output files
data_dir <- "eBirdData"
if (!dir.exists(data_dir)) {
dir.create(data_dir) }
f_ebd <- file.path(data_dir, "sampledata.txt")
# only run if the files don't already exist
if (!file.exists(f_ebd)) {
f_sampling <- file.path(data_dir, "ebd_US-AL-101_202204_202204_relApr-2022.txt")
auk_filter(ebd_filters, file = f_ebd, file_sampling = f_sampling, overwrite = TRUE)
}
View(f_ebd)
ebd$col_idx$name
## Remove unneed Columns
cols <- c("global unique identifier", "taxonomic order", "common name", "observation count", "county", "county code", "observation date", "sampling event identifier", "protocol type", "all species reported", "group identifier")
f_select <- "eBirdData/ebd_smaller.txt"
selected <- auk_ebd(f_ebd) %>%
auk_select(select = cols, file = f_select) %>%
read_ebd()
glimpse(selected)
# file size difference
file.size(f_ebd) / file.size(f_select)
## Creating a subset of the dataset
ebd_filters <- ebd %>%
# restrict to the standard traveling and stationary count protocols
auk_protocol(protocol = c("Stationary", "Traveling")) %>%
# restrict to only observations from Orange County, Florida
auk_county("Orange", replace = FALSE) %>%
auk_complete()
ebd_filters
## Remove unneed Columns
cols <- c("global unique identifier", "taxonomic order", "common name", "observation count", "county", "county code", "observation date", "sampling event identifier", "protocol type", "all species reported", "group identifier")
f_select <- "eBirdData/ebd_smaller.txt"
selected <- auk_ebd(f_ebd) %>%
auk_select(select = cols, file = f_select) %>%
read_ebd()
glimpse(selected)
# file size difference
file.size(f_ebd) / file.size(f_select)
## Creating a subset of the dataset
ebd_filters <- ebd %>%
# restrict to the standard traveling and stationary count protocols
auk_protocol(protocol = c("Stationary", "Traveling")) %>%
# restrict to only observations from Orange County, Florida
auk_county("Orange", replace = FALSE) %>%
auk_complete()
ebd_filters
install.packages("formatR")
hurricanesFL.df <- Hurricanes.df[grep("FL", Hurricanes.df$States)]
View(hurricanesFL.df)
library(readxl)
# excel_sheets('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Hurricane Impacts.xlsx')
Hurricanes.df = read_excel('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Hurricane Impacts.xlsx',sheet = 'RawData')
head(Hurricanes.df)
hurricanesFL.df <- Hurricanes.df[grep("FL", Hurricanes.df$States)]
View(hurricanesFL.df)
colnames((Hurricanes.df))
TrimmedHurricane.df = c[Hurricanes.df$#/Date, Hurricanes.df$Max Winds, Hurricanes.df$SS, Hurricanes.df$States ,Hurricanes.df$Storm ]
head(TrimmedHurricane.df)
```{r Hurricane Dataset, echo = FALSE}
library(readxl)
# excel_sheets('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Hurricane Impacts.xlsx')
Hurricanes.df = read_excel('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Hurricane Impacts.xlsx',sheet = 'RawData')
head(Hurricanes.df)
colnames((Hurricanes.df))
```{r Hurricane Dataset, echo = FALSE}
library(readxl)
# excel_sheets('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Hurricane Impacts.xlsx')
Hurricanes.df = read_excel('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Hurricane Impacts.xlsx',sheet = 'RawData')
head(Hurricanes.df)
colnames((Hurricanes.df))
library(readxl)
# excel_sheets('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Hurricane Impacts.xlsx')
Hurricanes.df = read_excel('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Hurricane Impacts.xlsx',sheet = 'RawData')
head(Hurricanes.df)
colnames((Hurricanes.df))
Hurricanes.df = read_excel('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Hurricane Impacts.xlsx',sheet = 'RawData')
library(readxl)
# excel_sheets('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Hurricane Impacts.xlsx')
Hurricanes.df = read_excel('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Hurricane Impacts.xlsx',sheet = 'RawData')
head(Hurricanes.df)
colnames(Hurricanes.df)
library(readxl)
# excel_sheets('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Hurricane Impacts.xlsx')
Hurricanes.df = read_excel('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Hurricane Impacts.xlsx',sheet = 'RawData')
head(Hurricanes.df)
colnames(Hurricanes.df)
# Trimming columns
TrimmedHurricane.df = c[Hurricanes.df$Date, Hurricanes.df$MaxWinds_kt, Hurricanes.df$SS_HWS, Hurricanes.df$StatesAffected, Hurricanes.df$StormNames]
head(TrimmedHurricane.df)
TrimmedHurricane.df = Hurricanes.df[, c("Date", "MaxWinds_kt", "SS_HWS", "StatesAffected", "StormNames")]
head(TrimmedHurricane.df)
View(TrimmedHurricane.df)
hurricanesFL.df <- TrimmedHurricane.df[grep("FL", Hurricanes.df$States)]
View(hurricanesFL.df)
hurricanesFL.df <- TrimmedHurricane.df[grep("FL", Hurricanes.df$States), ]
View(hurricanesFL.df)
hurricanesFL.df <- TrimmedHurricane.df[grep("FL", Hurricanes.df$StatesAffected), ]
View(hurricanesFL.df)
gsub('$', '', hurricanesFL.df$Date)
gsub('*', '', hurricanesFL.df$Date)
View(hurricanesFL.df)
hurricanesFL.df$Date <- gsub('$', '', hurricanesFL.df$Date)
hurricanesFL.df$Date <- gsub('*', '', hurricanesFL.df$Date)
View(hurricanesFL.df)
hurricanesFL.df$Date <- sub(c('$','*'), '', hurricanesFL.df$Date)
View(hurricanesFL.df)
sub(c('$','*'), '', hurricanesFL.df)
View(hurricanesFL.df)
sub('$', '', hurricanesFL.df)
View(hurricanesFL.df)
sub(c('$','*'), '', hurricanesFL.df$Date)
View(hurricanesFL.df)
sub('$', '', hurricanesFL.df$Date)
View(hurricanesFL.df)
hurricanesFL.df$Date <- gsub("$", "", as.character(hurricanesFL.df$Date))
View(hurricanesFL.df)
hurricanesFL.df$Date <- gsub("$","",as.character(hurricanesFL.df$Date))
View(hurricanesFL.df)
hurricanesFL.df$Date <- gsub("$","",as.character(hurricanesFL.df$Date))
View(hurricanesFL.df)
hurricanesFL.df[c('StartDate', 'StopDate', 'Year')] <- str_split_fixed(hurricanesFL.df$Date, '/', 3)
View(hurricanesFL.df)
hurricanesFL.df <- subset (hurricanesFL.df, select = -c('StartDate', 'StopDate'))
View(hurricanesFL.df)
hurricanesFL.df <- subset(hurricanesFL.df, select = -c(StartDate, StopDate))
View(hurricanesFL.df)
hurricanesFL.df <- subset(hurricanesFL.df, select = -c(Date, StartDate, StopDate))
View(hurricanesFL.df)
hurricanesFL.df <- subset(hurricanesFL.df, select = -c(Date))
View(hurricanesFL.df)
hurricanesFL.df <- substr(hurricanesFL.df$Year, 1, 4)
View(hurricanesFL.df)
library(readxl)
# excel_sheets('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Hurricane Impacts.xlsx')
Hurricanes.df = read_excel('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Hurricane Impacts.xlsx',sheet = 'RawData')
head(Hurricanes.df)
colnames(Hurricanes.df)
# Trimming columns. I only need the columns that indicate the Year, Max Wind Speed, Category, and whether the hurricane hit Florida.
TrimmedHurricane.df = Hurricanes.df[, c("Date", "MaxWinds_kt", "SS_HWS", "StatesAffected", "StormNames")]
head(TrimmedHurricane.df)
hurricanesFL.df <- TrimmedHurricane.df[grep("FL", Hurricanes.df$StatesAffected), ]
# Split Date string at /
hurricanesFL.df[c('StartDate', 'StopDate', 'Year')] <- str_split_fixed(hurricanesFL.df$Date, '/', 3)
# Remove extra columns created
hurricanesFL.df <- subset(hurricanesFL.df, select = -c(Date, StartDate, StopDate))
# Extract first 4 characters from new Year column and replace values with new trimmed values
hurricanesFL.df$Year <- substr(hurricanesFL.df$Year, 1, 4)
View(hurricanesFL.df)
hurricanesFL.df <- subset(hurricanesFL.df, select = -c(StatesAffected))
View(hurricanesFL.df)
library(dplyr)
precip.df <- filter(precip.df$Year > 2001)
View(precip.df)
library(dplyr)
precip.df <- filter(precip.df, Year > 2001)
View(precip.df)
library(readxl)
precip.df = read_excel('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Weather Data.xlsx',sheet = 'Statewide Precip')
head(precip.df)
```
library(dplyr)
precip.df <- filter(precip.df, Year > 2001)
View(precip.df)
library(dplyr)
temp.df <- filter(precip.df, Year > 2001)
head(temp.df)
View(hurricanesFL.df)
```{r Trimming temp years, echo = FALSE}
library(dplyr)
hurricanesFL.df <- filter(hurricanesFL.df, Year > 2001)
View(hurricanesFL.df)
library(dplyr)
hurricanesFL.df <- filter(hurricanesFL.df, MaxWinds_kt == 100)
View(hurricanesFL.df)
names(precip.df)[names(precip.df)==”Annual”] <- “AnnualPrecip”
precip.df
library(dplyr)
precip.df <- rename(AnnualPrecip = Annual)
precip.df
View(precip.df)
precip.df <- rename(precip.df$AnnualPrecip = precip.df$Annual)
View(precip.df)
rename(precip.df, AnnualPrecip = Annual)
View(precip.df)
rename(precip.df, AnnualPrecip = Annual)
View(precip.df)
library(dplyr)
rename(precip.df, AnnualPrecip = Annual)
rename(temp.df, AnnualTemp = Annual)
FinalData.df <- merge(precip.df,temp.df,by = "Year")
View(FinalData.df)
# Trimming columns. I only need the Year and Annual columns.
precipAnnual.df = precip.df[, c("Year", "Annual")]
head(precip.df)
precipAnnual.df = precip.df[, c("Year", "Annual")]
head(precipAnnual.df)
FinalData.df <- merge(FinalData.df,hurricanesFL.df, by = "Year")
head(FinalData.df)
library(readxl)
# excel_sheets('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Weather Data.xlsx')
library(readxl)
precip.df = read_excel('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Weather Data.xlsx',sheet = 'Statewide Precip')
library(dplyr)
precip.df <- filter(precip.df, Year > 2001)
# Trimming columns. I only need the Year and Annual columns.
precipAnnual.df = precip.df[, c("Year", "Annual")]
View(precipAnnual.df)
temp.df = read_excel('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Weather Data.xlsx',sheet = 'Statewide Temperature')
library(dplyr)
temp.df <- filter(precip.df, Year > 2001)
# Trimming columns. I only need the Year and Annual columns.
tempAnnual.df = temp.df[, c("Year", "Annual")]
View(tempAnnual.df)
library(readxl)
# excel_sheets('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Weather Data.xlsx')
library(readxl)
precip.df = read_excel('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Weather Data.xlsx',sheet = 'StatewidePrecip')
library(dplyr)
precip.df <- filter(precip.df, Year > 2001)
# Trimming columns. I only need the Year and Annual columns.
precipAnnual.df = precip.df[, c("Year", "Annual")]
head(precipAnnual.df)
temp.df = read_excel('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Weather Data.xlsx',sheet = 'StatewideTemperature')
head(temp.df)
View(temp.df)
library(dplyr)
temp.df <- filter(temp.df, Year > 2001)
# Trimming columns. I only need the Year and Annual columns.
tempAnnual.df = temp.df[, c("Year", "Annual")]
View(tempAnnual.df)
View(hurricanesFL.df)
library(readxl)
# excel_sheets('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Hurricane Impacts.xlsx')
Hurricanes.df = read_excel('/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/Hurricane Impacts.xlsx',sheet = 'RawData')
# Trimming columns. I only need the columns that indicate the Year, Max Wind Speed, Category, and whether the hurricane hit Florida.
TrimmedHurricane.df = Hurricanes.df[, c("Date", "MaxWinds_kt", "SS_HWS", "StatesAffected", "StormNames")]
```
```{r Hurricane Cleanup, include = FALSE}
hurricanesFL.df <- TrimmedHurricane.df[grep("FL", Hurricanes.df$StatesAffected), ]
# Split Date string at /
library(stringr)
hurricanesFL.df[c('StartDate', 'StopDate', 'Year')] <- str_split_fixed(hurricanesFL.df$Date, '/', 3)
# Remove extra columns created and now un-needed StatesAffected column
hurricanesFL.df <- subset(hurricanesFL.df, select = -c(Date, StatesAffected, StartDate, StopDate))
# Extract first 4 characters from new Year column and replace values with new trimmed values
hurricanesFL.df$Year <- substr(hurricanesFL.df$Year, 1, 4)
```
```{r Trimming hurricane years, include = FALSE}
library(dplyr)
hurricanesFL.df <- filter(hurricanesFL.df, Year > 2001)
```{r Trimming hurricane Irma duplicate, include = FALSE}
library(dplyr)
hurricanesFL.df <- filter(hurricanesFL.df, MaxWinds_kt != 100)
View(hurricanesFL.df)
HurricanesAnnual.df <- hurricanesFL.df %>% group_by(Year) %>% summarize(avgCat = mean(SS_HWS), MaxWinds = max(MaxWinds_kt))
HurricanesAnnual.df
HurricanesAnnual.df <- hurricanesFL.df %>% group_by(Year) %>% summarize(HurriNum = count(Year), avgCat = mean(as.numeric(SS_HWS)), MaxWinds = max(MaxWinds_kt))
HurricanesAnnual.df
library(dplyr)
hurricanesFL.df <- filter(hurricanesFL.df, MaxWinds_kt != 100)
hurricanesFL.df$MaxWinds_kt <- as.numeric(hurricanesFL.df$MaxWinds_kt)
## GroupBy + Summarize
HurricanesAnnual.df <- hurricanesFL.df %>% group_by(Year) %>% summarize(HurriNum = count(Year), avgCat = mean(as.numeric(SS_HWS)), MaxWinds = max(MaxWinds_kt))
HurricanesAnnual.df
class(MaxWinds_kt)
class(hurricanesFL.df$MaxWinds_kt)
library(dplyr)
hurricanesFL.df <- filter(hurricanesFL.df, MaxWinds_kt != 100)
# Checking data classes
hurricanesFL.df$MaxWinds_kt <- as.numeric(hurricanesFL.df$MaxWinds_kt)
HurricanesAnnual.df$HurriNum <- count(hurricanesFL.df$Year)
HurricanesAnnual.df$HurriInt <- mean(hurricanesFL.df$SS_HWS)
HurricanesAnnual.df$HurriMaxWind <- max(hurricanesFL.df$MaxWinds_kt)
HurricanesAnnual.df
HurricanesAnnual.df %<% hurricanesFL.df %<% summarize(hurricanesFL.df, HurriNum = count(), HurriInt = mean(SS_HWS), HurriMaxWind = max(MaxWinds_kt))
HurricanesAnnual.df %>% hurricanesFL.df %>% summarize(hurricanesFL.df, HurriNum = count(), HurriInt = mean(SS_HWS), HurriMaxWind = max(MaxWinds_kt))
## Note: Auk is a package spcifically designed for working with eBird data.
## The following import steps attempt to follow published instructions found here:
## https://cornelllabofornithology.github.io/ebird-best-practices/ebird.html#ebird-extract
library(auk)
library(lubridate)
library(gridExtra)
library(tidyverse)
# resolve namespace conflicts
select <- dplyr::select
# setup data directory
dir.create("eBirdData", showWarnings = FALSE)
ebd <- auk_ebd("/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/eBird Orange County 2002-2021/ebd_US-FL-095_200201_202112_relJun-2022.txt", file_sampling = "/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/eBird Data ebd_US-FL_relMay-2022/ebd_sampling_relJun-2022.txt")
ebd$col_idx$name
View(ebd)
## Note: Auk is a package spcifically designed for working with eBird data.
## The following import steps attempt to follow published instructions found here:
## https://cornelllabofornithology.github.io/ebird-best-practices/ebird.html#ebird-extract
library(auk)
library(lubridate)
library(gridExtra)
library(tidyverse)
# resolve namespace conflicts
select <- dplyr::select
# setup data directory
dir.create("eBirdData", showWarnings = FALSE)
ebd <- auk_ebd("/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/eBird Orange County 2002-2021/ebd_US-FL-095_200201_202112_relJun-2022.txt", file_sampling = "/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/eBird Data ebd_US-FL_relMay-2022/ebd_sampling_relJun-2022.txt")
ebd$col_idx$name
## Remove un-need Columns by saying which columns to keep
cols <- c("global unique identifier", "taxonomic order", "common name", "observation count", "county", "county code", "observation date", "sampling event identifier", "protocol type", "all species reported", "group identifier")
f_select <- "data/ebd_smaller.txt"
selected <- auk_ebd(f_ebd) %>%
auk_select(select = cols, file = f_select) %>%
read_ebd()
glimpse(selected)
# file size difference
file.size(f_ebd) / file.size(f_select)
## Creating a subset of the dataset
ebd_filters <- ebd %>%
# restrict to the standard traveling and stationary count protocols
auk_protocol(protocol = c("Stationary", "Traveling")) %>%
# restrict to only observations from Orange County, Florida
auk_complete()
ebd_filters
# output files
data_dir <- "eBirdData"
if (!dir.exists(data_dir)) {
dir.create(data_dir) }
f_ebd <- file.path(data_dir, "ebd_US-FL-095_200201_202112_relJun-2022.txt")
# only run if the files don't already exist
if (!file.exists(f_ebd)) {
f_sampling <- file.path(data_dir, "ebd_sampling_relJun-2022.txt")
auk_filter(ebd_filters, file = f_ebd, file_sampling = f_sampling)
}
View(f_ebd)
## Note: Auk is a package spcifically designed for working with eBird data.
## The following import steps attempt to follow published instructions found here:
## https://cornelllabofornithology.github.io/ebird-best-practices/ebird.html#ebird-extract
library(auk)
library(lubridate)
library(gridExtra)
library(tidyverse)
# resolve namespace conflicts
select <- dplyr::select
# setup data directory
dir.create("eBirdData", showWarnings = FALSE)
ebd <- auk_ebd("/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/eBird Orange County 2002-2021/ebd_US-FL-095_200201_202112_relJun-2022.txt", file_sampling = "/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/eBird Data ebd_US-FL_relMay-2022/ebd_sampling_relJun-2022.txt")
ebd$col_idx$name
## Remove un-need Columns by saying which columns to keep
cols <- c("global unique identifier", "taxonomic order", "common name", "observation count", "county", "county code", "observation date", "sampling event identifier", "protocol type", "all species reported", "group identifier")
f_select <- "data/ebd_smaller.txt"
selected <- auk_ebd(f_ebd) %>%
auk_select(select = cols, file = f_select) %>%
read_ebd()
glimpse(selected)
# file size difference
file.size(f_ebd) / file.size(f_select)
## Creating a subset of the dataset
ebd_filters <- ebd %>%
# restrict to the standard traveling and stationary count protocols
auk_protocol(protocol = c("Stationary", "Traveling")) %>%
# restrict to only observations from Orange County, Florida
auk_complete()
ebd_filters
# output files
data_dir <- "eBirdData"
if (!dir.exists(data_dir)) {
dir.create(data_dir) }
f_ebd <- file.path(data_dir, "ebd_US-FL-095_200201_202112_relJun-2022.txt")
# only run if the files don't already exist
if (!file.exists(f_ebd)) {
f_sampling <- file.path(data_dir, "ebd_sampling_relJun-2022.txt")
auk_filter(ebd_filters, file = f_ebd, file_sampling = f_sampling)
}
View(f_ebd)
## Note: Auk is a package spcifically designed for working with eBird data.
## The following import steps attempt to follow published instructions found here:
## https://cornelllabofornithology.github.io/ebird-best-practices/ebird.html#ebird-extract
library(auk)
library(lubridate)
library(gridExtra)
library(tidyverse)
# resolve namespace conflicts
select <- dplyr::select
# setup data directory
dir.create("eBirdData", showWarnings = FALSE)
ebd <- auk_ebd("/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/eBird Orange County 2002-2021/ebd_US-FL-095_200201_202112_relJun-2022.txt", file_sampling = "/Users/kimberlyadams/Documents/GitHub/DSC520-Statistics-and-R/data/Project/eBird Data ebd_US-FL_relMay-2022/ebd_sampling_relJun-2022.txt")
ebd$col_idx$name
## Remove un-need Columns by saying which columns to keep
cols <- c("global unique identifier", "taxonomic order", "common name", "observation count", "county", "county code", "observation date", "sampling event identifier", "protocol type", "all species reported", "group identifier")
f_select <- "data/ebd_smaller.txt"
selected <- auk_ebd(f_ebd) %>%
auk_select(select = cols, file = f_select) %>%
read_ebd()
glimpse(selected)
# file size difference
file.size(f_ebd) / file.size(f_select)
## Creating a subset of the dataset
ebd_filters <- ebd %>%
# restrict to the standard traveling and stationary count protocols
auk_protocol(protocol = c("Stationary", "Traveling")) %>%
# restrict to only observations from Orange County, Florida
auk_complete()
ebd_filters
f_ebd <- file.path(data_dir, "ebd_US-FL-095_200201_202112_relJun-2022.txt")
View(f_ebd)
HurricanesAnnual.df
hurricanesFL.df <- subset(hurricanesFL.df, select = -c(StormNames))
HurricanesAnnual.df
# install.packages("remotes")
# remotes::install_github("mstrimas/ebppackages")
## Set the working directory
setwd("/Users/kimberlyadams/Documents/Bellevue Masters in Data Science/3 Statistics and R/Project/AUKPractice/")
# set ebd path
auk::auk_set_ebd_path("/data/ebird")
library(auk)
library(lubridate)
library(sf)
library(gridExtra)
library(tidyverse)
# resolve namespace conflicts
select <- dplyr::select
# setup data directory
dir.create("data", showWarnings = FALSE)
ebd <- auk_ebd("ebd_woothr_june_bcr27.txt",
file_sampling = "ebd_checklists_june_bcr27.txt")
ebd_filters <- ebd %>%
auk_species("Wood Thrush") %>%
# southeastern coastal plain bcr
auk_bcr(bcr = 27) %>%
# june, use * to get data from any year
auk_date(date = c("*-06-01", "*-06-30")) %>%
# restrict to the standard traveling and stationary count protocols
auk_protocol(protocol = c("Stationary", "Traveling")) %>%
auk_complete()
# Double check the filters you have defined
ebd_filters
# output files
data_dir <- "data"
if (!dir.exists(data_dir)) {
dir.create(data_dir)
}
f_ebd <- file.path(data_dir, "ebd_woothr_june_bcr27.txt")
f_sampling <- file.path(data_dir, "ebd_checklists_june_bcr27.txt")
# only run if the files don't already exist
if (!file.exists(f_ebd)) {
auk_filter(ebd_filters, file = f_ebd, file_sampling = f_sampling)
}
ebd_zf <- auk_zerofill(f_ebd, f_sampling, collapse = TRUE)
# function to convert time observation to hours since midnight
time_to_decimal <- function(x) {
x <- hms(x, quiet = TRUE)
hour(x) + minute(x) / 60 + second(x) / 3600
}
# clean up variables
ebd_zf <- ebd_zf %>%
mutate(
# convert X to NA
observation_count = if_else(observation_count == "X",
NA_character_, observation_count),
observation_count = as.integer(observation_count),
# effort_distance_km to 0 for non-travelling counts
effort_distance_km = if_else(protocol_type != "Traveling",
0, effort_distance_km),
# convert time to decimal hours since midnight
time_observations_started = time_to_decimal(time_observations_started),
# split date into year and day of year
year = year(observation_date),
day_of_year = yday(observation_date)
)
ebird <- ebd_zf_filtered %>%
select(checklist_id, observer_id, sampling_event_identifier,
scientific_name,
observation_count, species_observed,
state_code, locality_id, latitude, longitude,
protocol_type, all_species_reported,
observation_date, year, day_of_year,
time_observations_started,
duration_minutes, effort_distance_km,
number_observers)
write_csv(ebird, "data/ebd_woothr_june_bcr27_zf.csv", na = "")
